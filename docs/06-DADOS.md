# üóÑÔ∏è M√≥dulo 6: Gest√£o de Dados

## üìã Vis√£o Geral

Este m√≥dulo aborda o gerenciamento completo dos dados do sistema de monitoramento IF-UFG, incluindo bancos de dados, backup, restore, reten√ß√£o e otimiza√ß√£o de performance.

## üóÉÔ∏è Estrutura dos Dados

### **Bancos de Dados Utilizados**

| **Sistema** | **Tipo** | **Localiza√ß√£o** | **Fun√ß√£o** |
|-------------|----------|-----------------|------------|
| **SQLite** | Relacional | `/backend/alerting/data/alerts.db` | Alertas e sensores |
| **Prometheus** | Time Series | `/backend/prometheus/data/` | M√©tricas e hist√≥rico |
| **Grafana** | SQLite | `/backend/grafana/data/grafana.db` | Dashboards e usu√°rios |

### **Esquema do Banco SQLite (Alertas)**

```sql
-- Tabela de alertas
CREATE TABLE alerts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    sensor_id TEXT NOT NULL,
    alert_type TEXT NOT NULL,
    alert_level TEXT NOT NULL,
    description TEXT,
    value REAL,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    email_sent BOOLEAN DEFAULT FALSE,
    resolved BOOLEAN DEFAULT FALSE,
    INDEX(sensor_id),
    INDEX(timestamp),
    INDEX(alert_level)
);

-- Tabela de dados dos sensores
CREATE TABLE sensor_data (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    sensor_id TEXT NOT NULL,
    temperature REAL,
    humidity REAL,
    wifi_rssi INTEGER,
    uptime INTEGER,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    INDEX(sensor_id),
    INDEX(timestamp)
);

-- Tabela de configura√ß√µes do sistema
CREATE TABLE system_config (
    key TEXT PRIMARY KEY,
    value TEXT,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Tabela de estat√≠sticas
CREATE TABLE statistics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    metric_name TEXT NOT NULL,
    metric_value REAL,
    sensor_id TEXT,
    period TEXT, -- hourly, daily, weekly
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    INDEX(metric_name),
    INDEX(timestamp)
);
```

## üíæ Backup e Restore

### **Script de Backup Completo**

```bash
#!/bin/bash
# utils/backup_completo.sh

BACKUP_DIR="/opt/cluster-monitoring/backups"
DATE=$(date '+%Y%m%d_%H%M%S')
BACKUP_PATH="$BACKUP_DIR/backup_$DATE"

echo "üîÑ Iniciando backup completo do sistema..."
echo "Timestamp: $(date)"
echo "Destino: $BACKUP_PATH"

# Criar diret√≥rio de backup
mkdir -p "$BACKUP_PATH"

# 1. Backup do banco SQLite (alertas)
echo "üìä Backup do banco de alertas..."
sqlite3 /opt/cluster-monitoring/backend/alerting/data/alerts.db ".backup '$BACKUP_PATH/alerts.db'"

# 2. Backup do Prometheus
echo "üìà Backup dos dados Prometheus..."
tar -czf "$BACKUP_PATH/prometheus_data.tar.gz" \
    -C /opt/cluster-monitoring/backend/prometheus/data .

# 3. Backup do Grafana
echo "üìä Backup do Grafana..."
tar -czf "$BACKUP_PATH/grafana_data.tar.gz" \
    -C /opt/cluster-monitoring/backend/grafana/data .

# 4. Backup das configura√ß√µes
echo "‚öôÔ∏è Backup das configura√ß√µes..."
tar -czf "$BACKUP_PATH/configs.tar.gz" \
    backend/alerting/config.py \
    backend/prometheus/prometheus.yml \
    backend/grafana/config/grafana.ini \
    backend/docker-compose.yaml

# 5. Backup dos logs
echo "üìù Backup dos logs..."
tar -czf "$BACKUP_PATH/logs.tar.gz" \
    -C /opt/cluster-monitoring/logs .

# 6. Backup dos scripts
echo "üîß Backup dos scripts..."
tar -czf "$BACKUP_PATH/scripts.tar.gz" \
    *.sh utils/*.sh

# 7. Criar manifesto do backup
cat > "$BACKUP_PATH/manifest.txt" << EOF
Backup do Sistema de Monitoramento IF-UFG
=========================================
Data: $(date)
Vers√£o: 2.0.0
Hostname: $(hostname)
Usuario: $(whoami)

Conte√∫do:
- alerts.db: Banco de alertas e dados dos sensores
- prometheus_data.tar.gz: Dados hist√≥ricos Prometheus
- grafana_data.tar.gz: Dashboards e configura√ß√µes Grafana
- configs.tar.gz: Arquivos de configura√ß√£o
- logs.tar.gz: Logs do sistema
- scripts.tar.gz: Scripts e utilit√°rios

Tamanhos:
$(du -sh "$BACKUP_PATH"/* | sed 's|'$BACKUP_PATH'/||')

Total: $(du -sh "$BACKUP_PATH" | cut -f1)
EOF

echo "‚úÖ Backup completo criado em: $BACKUP_PATH"
echo "üìä Tamanho total: $(du -sh "$BACKUP_PATH" | cut -f1)"

# Limpeza de backups antigos (manter √∫ltimos 10)
echo "üßπ Limpando backups antigos..."
cd "$BACKUP_DIR"
ls -1d backup_* | head -n -10 | xargs -r rm -rf

echo "‚úÖ Backup conclu√≠do com sucesso!"
```

### **Script de Restore**

```bash
#!/bin/bash
# utils/restaurar_backup.sh

if [ $# -ne 1 ]; then
    echo "Uso: $0 <diretorio_backup>"
    echo "Exemplo: $0 /opt/cluster-monitoring/backups/backup_20240703_143000"
    exit 1
fi

BACKUP_PATH="$1"

if [ ! -d "$BACKUP_PATH" ]; then
    echo "‚ùå Diret√≥rio de backup n√£o encontrado: $BACKUP_PATH"
    exit 1
fi

echo "üîÑ Iniciando restore do sistema..."
echo "Origem: $BACKUP_PATH"
echo "‚ö†Ô∏è  AVISO: Este processo ir√° substituir os dados atuais!"
read -p "Continuar? (s/N): " confirm

if [[ $confirm != [sS] ]]; then
    echo "‚ùå Restore cancelado pelo usu√°rio"
    exit 1
fi

# Parar sistema
echo "‚è∏Ô∏è Parando sistema..."
cd /opt/cluster-monitoring
./stop.sh

# 1. Restore do banco SQLite
if [ -f "$BACKUP_PATH/alerts.db" ]; then
    echo "üìä Restaurando banco de alertas..."
    cp "$BACKUP_PATH/alerts.db" backend/alerting/data/alerts.db
fi

# 2. Restore do Prometheus
if [ -f "$BACKUP_PATH/prometheus_data.tar.gz" ]; then
    echo "üìà Restaurando dados Prometheus..."
    rm -rf backend/prometheus/data/*
    tar -xzf "$BACKUP_PATH/prometheus_data.tar.gz" \
        -C backend/prometheus/data/
fi

# 3. Restore do Grafana
if [ -f "$BACKUP_PATH/grafana_data.tar.gz" ]; then
    echo "üìä Restaurando dados Grafana..."
    rm -rf backend/grafana/data/*
    tar -xzf "$BACKUP_PATH/grafana_data.tar.gz" \
        -C backend/grafana/data/
fi

# 4. Restore das configura√ß√µes
if [ -f "$BACKUP_PATH/configs.tar.gz" ]; then
    echo "‚öôÔ∏è Restaurando configura√ß√µes..."
    tar -xzf "$BACKUP_PATH/configs.tar.gz"
fi

# 5. Restore dos logs
if [ -f "$BACKUP_PATH/logs.tar.gz" ]; then
    echo "üìù Restaurando logs..."
    rm -rf logs/*
    tar -xzf "$BACKUP_PATH/logs.tar.gz" -C logs/
fi

# Corrigir permiss√µes
echo "üîß Corrigindo permiss√µes..."
sudo chown -R $USER:$USER /opt/cluster-monitoring
chmod +x *.sh utils/*.sh

# Reiniciar sistema
echo "‚ñ∂Ô∏è Reiniciando sistema..."
./start.sh

echo "‚úÖ Restore conclu√≠do com sucesso!"
echo "üîç Verificando sistema..."
sleep 10
./utils/verificar_sistema.sh
```

## üìà Gest√£o de Reten√ß√£o

### **Configura√ß√£o de Reten√ß√£o Prometheus**

```yaml
# backend/prometheus/prometheus.yml

global:
  scrape_interval: 30s
  evaluation_interval: 30s
  external_labels:
    cluster: 'ifufg-monitoring'

# Configura√ß√£o de reten√ß√£o
storage:
  tsdb:
    retention.time: 30d      # Manter 30 dias
    retention.size: 10GB     # M√°ximo 10GB
    wal-compression: true    # Compress√£o WAL

rule_files:
  - "rules/*.yml"

scrape_configs:
  - job_name: 'cluster-monitoring'
    static_configs:
      - targets: ['exporter:8000']
    scrape_interval: 30s
    metrics_path: /metrics
```

### **Script de Limpeza de Dados**

```bash
#!/bin/bash
# utils/limpar_dados_antigos.sh

echo "üßπ Iniciando limpeza de dados antigos..."

# Configura√ß√µes
RETENTION_DAYS=30
DB_PATH="/opt/cluster-monitoring/backend/alerting/data/alerts.db"

# 1. Limpar alertas antigos
echo "üóëÔ∏è Removendo alertas antigos (>$RETENTION_DAYS dias)..."
sqlite3 "$DB_PATH" "
DELETE FROM alerts 
WHERE timestamp < datetime('now', '-$RETENTION_DAYS days');
"

# 2. Limpar dados de sensores antigos
echo "üóëÔ∏è Removendo dados de sensores antigos (>$RETENTION_DAYS dias)..."
sqlite3 "$DB_PATH" "
DELETE FROM sensor_data 
WHERE timestamp < datetime('now', '-$RETENTION_DAYS days');
"

# 3. Limpar estat√≠sticas antigas
echo "üóëÔ∏è Removendo estat√≠sticas antigas (>$RETENTION_DAYS dias)..."
sqlite3 "$DB_PATH" "
DELETE FROM statistics 
WHERE timestamp < datetime('now', '-$RETENTION_DAYS days');
"

# 4. Otimizar banco
echo "‚ö° Otimizando banco de dados..."
sqlite3 "$DB_PATH" "VACUUM;"
sqlite3 "$DB_PATH" "ANALYZE;"

# 5. Limpar logs antigos
echo "üóëÔ∏è Removendo logs antigos..."
find /opt/cluster-monitoring/logs -name "*.log" -mtime +$RETENTION_DAYS -delete
find /opt/cluster-monitoring/logs -name "*.log.*" -mtime +$RETENTION_DAYS -delete

# 6. Limpar backups antigos
echo "üóëÔ∏è Removendo backups antigos..."
find /opt/cluster-monitoring/backups -name "backup_*" -mtime +60 -exec rm -rf {} \;

# Estat√≠sticas finais
echo "üìä Estat√≠sticas p√≥s-limpeza:"
echo "- Alertas: $(sqlite3 "$DB_PATH" "SELECT COUNT(*) FROM alerts;")"
echo "- Dados sensores: $(sqlite3 "$DB_PATH" "SELECT COUNT(*) FROM sensor_data;")"
echo "- Tamanho banco: $(du -h "$DB_PATH" | cut -f1)"
echo "- Espa√ßo em disco: $(df -h /opt/cluster-monitoring | tail -n 1 | awk '{print $4}') livres"

echo "‚úÖ Limpeza conclu√≠da!"
```

### **Agendamento Autom√°tico (Cron)**

```bash
# Configurar limpeza autom√°tica
crontab -e

# Adicionar linhas:
# Backup di√°rio √†s 2h
0 2 * * * /opt/cluster-monitoring/utils/backup_completo.sh >> /opt/cluster-monitoring/logs/backup.log 2>&1

# Limpeza semanal aos domingos √†s 3h
0 3 * * 0 /opt/cluster-monitoring/utils/limpar_dados_antigos.sh >> /opt/cluster-monitoring/logs/cleanup.log 2>&1

# Verifica√ß√£o do sistema a cada 6 horas
0 */6 * * * /opt/cluster-monitoring/utils/verificar_sistema.sh >> /opt/cluster-monitoring/logs/health.log 2>&1
```

## üìä An√°lise e Relat√≥rios

### **Script de Estat√≠sticas**

```python
#!/usr/bin/env python3
# utils/gerar_relatorio.py

import sqlite3
import json
import matplotlib.pyplot as plt
import pandas as pd
from datetime import datetime, timedelta
import sys

class RelatorioSistema:
    def __init__(self, db_path):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
    
    def obter_estatisticas_gerais(self):
        """Obter estat√≠sticas gerais do sistema"""
        cursor = self.conn.cursor()
        
        # Total de alertas
        cursor.execute("SELECT COUNT(*) FROM alerts")
        total_alertas = cursor.fetchone()[0]
        
        # Alertas por n√≠vel
        cursor.execute("""
            SELECT alert_level, COUNT(*) 
            FROM alerts 
            GROUP BY alert_level
        """)
        alertas_por_nivel = dict(cursor.fetchall())
        
        # Alertas nas √∫ltimas 24h
        cursor.execute("""
            SELECT COUNT(*) FROM alerts 
            WHERE timestamp > datetime('now', '-24 hours')
        """)
        alertas_24h = cursor.fetchone()[0]
        
        # Sensores ativos
        cursor.execute("""
            SELECT COUNT(DISTINCT sensor_id) FROM sensor_data 
            WHERE timestamp > datetime('now', '-5 minutes')
        """)
        sensores_ativos = cursor.fetchone()[0]
        
        return {
            'total_alertas': total_alertas,
            'alertas_por_nivel': alertas_por_nivel,
            'alertas_24h': alertas_24h,
            'sensores_ativos': sensores_ativos,
            'timestamp': datetime.now().isoformat()
        }
    
    def obter_dados_sensores(self, horas=24):
        """Obter dados dos sensores das √∫ltimas N horas"""
        query = """
            SELECT sensor_id, temperature, humidity, wifi_rssi, timestamp
            FROM sensor_data
            WHERE timestamp > datetime('now', '-{} hours')
            ORDER BY timestamp DESC
        """.format(horas)
        
        df = pd.read_sql_query(query, self.conn)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        
        return df
    
    def gerar_grafico_temperatura(self, output_path='temperatura_relatorio.png'):
        """Gerar gr√°fico de temperatura"""
        df = self.obter_dados_sensores(24)
        
        if df.empty:
            print("Sem dados para gerar gr√°fico")
            return
        
        plt.figure(figsize=(12, 6))
        
        for sensor in df['sensor_id'].unique():
            sensor_data = df[df['sensor_id'] == sensor]
            plt.plot(sensor_data['timestamp'], sensor_data['temperature'], 
                    label=f'Sensor {sensor}', linewidth=2)
        
        plt.title('Temperatura por Sensor - √öltimas 24 Horas')
        plt.xlabel('Hor√°rio')
        plt.ylabel('Temperatura (¬∞C)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"Gr√°fico salvo em: {output_path}")
    
    def gerar_relatorio_html(self, output_path='relatorio.html'):
        """Gerar relat√≥rio HTML completo"""
        stats = self.obter_estatisticas_gerais()
        df = self.obter_dados_sensores(24)
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Relat√≥rio - Sistema IF-UFG</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ background-color: #2e7d32; color: white; padding: 20px; text-align: center; }}
                .stats {{ display: flex; justify-content: space-around; margin: 20px 0; }}
                .stat-box {{ background-color: #f5f5f5; padding: 15px; text-align: center; border-radius: 5px; }}
                table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>Relat√≥rio do Sistema de Monitoramento</h1>
                <p>Instituto de F√≠sica - UFG</p>
                <p>Gerado em: {stats['timestamp']}</p>
            </div>
            
            <div class="stats">
                <div class="stat-box">
                    <h3>{stats['total_alertas']}</h3>
                    <p>Total de Alertas</p>
                </div>
                <div class="stat-box">
                    <h3>{stats['alertas_24h']}</h3>
                    <p>Alertas (24h)</p>
                </div>
                <div class="stat-box">
                    <h3>{stats['sensores_ativos']}</h3>
                    <p>Sensores Ativos</p>
                </div>
            </div>
            
            <h2>Alertas por N√≠vel</h2>
            <table>
                <tr><th>N√≠vel</th><th>Quantidade</th></tr>
        """
        
        for nivel, count in stats['alertas_por_nivel'].items():
            html += f"<tr><td>{nivel}</td><td>{count}</td></tr>"
        
        html += """
            </table>
            
            <h2>Dados Recentes dos Sensores</h2>
            <table>
                <tr><th>Sensor</th><th>Temperatura</th><th>Umidade</th><th>WiFi RSSI</th><th>Timestamp</th></tr>
        """
        
        for _, row in df.head(20).iterrows():
            html += f"""
                <tr>
                    <td>{row['sensor_id']}</td>
                    <td>{row['temperature']:.1f}¬∞C</td>
                    <td>{row['humidity']:.1f}%</td>
                    <td>{row['wifi_rssi']} dBm</td>
                    <td>{row['timestamp']}</td>
                </tr>
            """
        
        html += """
            </table>
        </body>
        </html>
        """
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html)
        
        print(f"Relat√≥rio HTML salvo em: {output_path}")
    
    def __del__(self):
        if hasattr(self, 'conn'):
            self.conn.close()

def main():
    db_path = "/opt/cluster-monitoring/backend/alerting/data/alerts.db"
    
    if len(sys.argv) > 1:
        db_path = sys.argv[1]
    
    relatorio = RelatorioSistema(db_path)
    
    print("üìä Gerando relat√≥rio do sistema...")
    
    # Estat√≠sticas gerais
    stats = relatorio.obter_estatisticas_gerais()
    print(f"üìà Total de alertas: {stats['total_alertas']}")
    print(f"üîî Alertas 24h: {stats['alertas_24h']}")
    print(f"üì° Sensores ativos: {stats['sensores_ativos']}")
    
    # Gerar gr√°ficos
    relatorio.gerar_grafico_temperatura()
    
    # Gerar relat√≥rio HTML
    relatorio.gerar_relatorio_html()
    
    print("‚úÖ Relat√≥rio conclu√≠do!")

if __name__ == "__main__":
    main()
```

## üîç Consultas √öteis

### **Queries SQLite para An√°lise**

```sql
-- 1. Alertas por sensor nas √∫ltimas 24 horas
SELECT sensor_id, alert_type, COUNT(*) as count
FROM alerts 
WHERE timestamp > datetime('now', '-24 hours')
GROUP BY sensor_id, alert_type
ORDER BY count DESC;

-- 2. M√©dia de temperatura por sensor (√∫ltimos 7 dias)
SELECT sensor_id, 
       AVG(temperature) as temp_media,
       MIN(temperature) as temp_minima,
       MAX(temperature) as temp_maxima
FROM sensor_data 
WHERE timestamp > datetime('now', '-7 days')
GROUP BY sensor_id;

-- 3. Sensores com maior n√∫mero de alertas
SELECT sensor_id, COUNT(*) as total_alertas
FROM alerts 
GROUP BY sensor_id 
ORDER BY total_alertas DESC;

-- 4. Hist√≥rico de uptime dos sensores
SELECT sensor_id, 
       MAX(uptime) as max_uptime,
       COUNT(*) as readings
FROM sensor_data 
WHERE timestamp > datetime('now', '-24 hours')
GROUP BY sensor_id;

-- 5. Alertas por hora do dia (padr√µes)
SELECT strftime('%H', timestamp) as hora,
       COUNT(*) as alertas
FROM alerts 
WHERE timestamp > datetime('now', '-7 days')
GROUP BY hora 
ORDER BY hora;

-- 6. Qualidade da rede WiFi por sensor
SELECT sensor_id,
       AVG(wifi_rssi) as rssi_medio,
       MIN(wifi_rssi) as rssi_minimo,
       COUNT(*) as leituras
FROM sensor_data 
WHERE timestamp > datetime('now', '-24 hours')
GROUP BY sensor_id;
```

### **Scripts de Monitoramento**

```bash
#!/bin/bash
# utils/monitorar_performance.sh

echo "=== Monitoramento de Performance ==="
echo "Timestamp: $(date)"

# Tamanho dos bancos
echo "üìä Tamanho dos Bancos:"
echo "SQLite Alertas: $(du -h /opt/cluster-monitoring/backend/alerting/data/alerts.db | cut -f1)"
echo "Prometheus: $(du -sh /opt/cluster-monitoring/backend/prometheus/data | cut -f1)"
echo "Grafana: $(du -h /opt/cluster-monitoring/backend/grafana/data/grafana.db | cut -f1)"

# N√∫mero de registros
echo
echo "üìà N√∫mero de Registros:"
DB_PATH="/opt/cluster-monitoring/backend/alerting/data/alerts.db"
echo "Alertas: $(sqlite3 "$DB_PATH" "SELECT COUNT(*) FROM alerts;")"
echo "Dados Sensores: $(sqlite3 "$DB_PATH" "SELECT COUNT(*) FROM sensor_data;")"

# Performance das queries
echo
echo "‚ö° Performance de Queries:"
time sqlite3 "$DB_PATH" "SELECT COUNT(*) FROM sensor_data WHERE timestamp > datetime('now', '-24 hours');" > /dev/null

# Espa√ßo em disco
echo
echo "üíæ Espa√ßo em Disco:"
df -h /opt/cluster-monitoring | tail -n 1

# Uso de mem√≥ria dos containers
echo
echo "üê≥ Uso de Mem√≥ria dos Containers:"
docker stats --no-stream --format "table {{.Name}}\t{{.MemUsage}}\t{{.MemPerc}}"
```

## üîß Otimiza√ß√£o

### **√çndices de Performance**

```sql
-- Criar √≠ndices para melhorar performance
CREATE INDEX IF NOT EXISTS idx_alerts_sensor_timestamp 
ON alerts(sensor_id, timestamp);

CREATE INDEX IF NOT EXISTS idx_alerts_level 
ON alerts(alert_level);

CREATE INDEX IF NOT EXISTS idx_sensor_data_timestamp 
ON sensor_data(timestamp);

CREATE INDEX IF NOT EXISTS idx_sensor_data_sensor 
ON sensor_data(sensor_id);

-- Analisar estat√≠sticas
ANALYZE;
```

### **Configura√ß√£o de Memory para SQLite**

```python
# Configura√ß√µes de performance SQLite
def configurar_sqlite_performance(conn):
    """Configurar SQLite para melhor performance"""
    cursor = conn.cursor()
    
    # Configura√ß√µes de performance
    cursor.execute("PRAGMA cache_size = 10000")      # 10k p√°ginas em cache
    cursor.execute("PRAGMA temp_store = MEMORY")     # Usar mem√≥ria para temp
    cursor.execute("PRAGMA journal_mode = WAL")      # Write-Ahead Logging
    cursor.execute("PRAGMA synchronous = NORMAL")    # Sync normal
    cursor.execute("PRAGMA foreign_keys = ON")       # Chaves estrangeiras
    
    conn.commit()
```

## üõ†Ô∏è Troubleshooting

### **Problemas Comuns**

| **Problema** | **Sintoma** | **Solu√ß√£o** |
|--------------|-------------|-------------|
| **Banco corrupto** | Erro SQLite | Restore do backup |
| **Espa√ßo insuficiente** | Disco cheio | Limpeza de dados antigos |
| **Performance lenta** | Queries demoradas | Criar √≠ndices, otimizar |
| **Backup falhou** | Erro no script | Verificar permiss√µes |
| **Dados inconsistentes** | Valores an√¥malos | Valida√ß√£o e limpeza |

### **Comandos de Diagn√≥stico**

```bash
# Verificar integridade do banco
sqlite3 /opt/cluster-monitoring/backend/alerting/data/alerts.db "PRAGMA integrity_check;"

# Verificar estat√≠sticas do banco
sqlite3 /opt/cluster-monitoring/backend/alerting/data/alerts.db "PRAGMA table_info(alerts);"

# Verificar espa√ßo em disco
df -h /opt/cluster-monitoring

# Verificar processos que usam o banco
lsof /opt/cluster-monitoring/backend/alerting/data/alerts.db

# Testar performance de queries
time sqlite3 /opt/cluster-monitoring/backend/alerting/data/alerts.db "SELECT COUNT(*) FROM sensor_data;"
```

## üìã Checklist de Manuten√ß√£o

### **Di√°rio**
- [ ] Verificar espa√ßo em disco
- [ ] Verificar integridade dos servi√ßos
- [ ] Monitorar logs de erro

### **Semanal**
- [ ] Executar limpeza de dados antigos
- [ ] Verificar performance das queries
- [ ] Validar backups

### **Mensal**
- [ ] Otimizar bancos (VACUUM/ANALYZE)
- [ ] Gerar relat√≥rio de estat√≠sticas
- [ ] Revisar reten√ß√£o de dados
- [ ] Atualizar documenta√ß√£o

---

**üìç Pr√≥ximo M√≥dulo**: [7. Troubleshooting](07-TROUBLESHOOTING.md)  
**üè† Voltar**: [Manual Principal](README.md) 